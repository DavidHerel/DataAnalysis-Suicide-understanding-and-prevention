---
title: "Suicide Notebook"
author: "David Herel"
date: "14.12.2020"
output:
  html_document:
    toc: true
    df_print: paged
    theme: readable
    highlight: tango
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
 
## Introduction

In this notebook I want to make a closer look on Suicide dataset and analyze it.

## Part I - Exploratory analysis of the suicide dataset
Load the dataset, visualize the main relationships and trends, 
preprocess the data, carry out dimensionality reduction and clustering. The main goal is to see whether there are
regularities in suicide rates across countries, continents, periods of times, etc.

### Analyze variables
So what about to start with analyzing dataset?
At **first**, we look on interesting variables and their behavior.

Let's start with most interesting one: 

#### Generation

#![Generation](ok_boomer.jpg)

```{r message = FALSE, warning = FALSE} 
#load data in to "data"
load(file="suicide.RData")

barplot(table(data$generation),col = rainbow(20))
```

We can see that generation **G.I.** and **Z** are not so big as others. My explanation is that we can view all generations as **Gauss distribution**, where **G.I.** is at the start of distribution and **generation Z** is at the end of distribution. Both generation dont have so many people in their group, because either they are too old or too young

#### Sex

```{r message = FALSE, warning = FALSE}
barplot(table(data$sex), col=c("pink", "blue"))
```

We can see we **same number** of males in females in dataset.

#### Age

```{r message = FALSE, warning = FALSE}
barplot(table(data$age), col="blue")
```

This is really **weird** for me. I would not divide data in these categories. I would make one category **for each age**. But I guess they chosed these categories because that makes data **equally distributed**.

#### Continent

```{r message = FALSE, warning = FALSE}
barplot(table(data$continent), col="blue")
```

I wanted to have a look on **countries** at first. But there were too many of them and it was **difficult** to read.

So when we switch to continents. We can see most data comes from **Europe and America**. 

So it is possible that the models and prediction will be more accurate for **them** and not so good for **other continents** like Africa or Oceania.

### Analyze correlations
Now we analyzed key variables and it is time to move on some **'high-level'** charts like interesting corelations.

#### Suicide ratio
What about overall **suicide rate**? Is it increasing, decreasing or stagnating?
```{r message = FALSE, warning = FALSE}
#libraries
library(magrittr) 
library(dplyr) 
library(ggplot2)


data_plot_suicide = data %>% # using suicide_data
  group_by(year) %>% # group all the data from the same year
  summarize(
            suicides_100k = (sum(suicides_no) / sum(population)) * 100000)

ggplot(data = data_plot_suicide, 
                      aes(x = year, y = suicides_100k)) +
  # points to each peak
  geom_point(col = 'blue') +
  
  # line of points
  geom_line(col = 'blue') +
  
  #change labels
  ylab('Suicides global per 100k') +
  xlab('Year')
  

```

We can see that overall trend is that suicide rate is **decreasing overtime**. 
And this greatly shows how statistics **can be wrong**, because our world is too complex to be predict by these models! (For now)

If we see this **model**. Everyone would predict that in couple of years the suicide rate will be even lower. But **COVID-19** hit. And we can see that suicides are massively increasing [^1] [^2]. 

To have a **correct** prediction we would have to develop model which can predict, when war **strikes or pandemic strikes** etc. And that is impossible in **near future**, in my opinion. 


[^1]: Gunnell D, Appleby L, Arensman E, et al., COVID-19 Suicide Prevention Research Collaboration. Suicide risk and prevention during the COVID-19 pandemic. Lancet Psychiatry2020;7:468-71. doi:10.1016/S2215-0366(20)30171-1 pmid:32330430
[^2]: Reger MA, Stanley IH, Joiner TE. Suicide mortality and coronavirus disease 2019: a perfect storm?JAMA Psychiatry2020. [Epub ahead of print.] doi:10.1001/jamapsychiatry.2020.1060 pmid:32275300

#### Man vs female
This statistics should be pretty **accurate** because there is equal number man and woman in dataset.

```{r message = FALSE, warning = FALSE}
library("pdp")

#same as in previous for global age
suicide_data_sex = data %>%
  group_by(year, sex) %>%
  summarize(suicide_100k = (sum(suicides_no) / sum(population)) * 100000)
  
  
ggplot(data = suicide_data_sex, 
       aes(x = year, y = suicide_100k, col = factor(sex))) + 
  facet_grid(sex ~ ., scales = "free_y") + 
  
  geom_line() + 
  geom_point() +
  
  #change labels
  xlab('Year') +
  ylab('Suicides global per 100k')+
  
  #change legend -> from factor(sex) to sex
  labs(color = 'Sex')



```

We see that **males** have a lot more suicides than **females**. There is not a single year, when females 'wins'. We could maybe use classical barplot for overall result, but I was more interested in **timeline** and how or if it changed.

#### Continents
There we will not get accurate results because, as I showed few sections before, we have far far more data from Europe/America than from other continents. So there can be huge **innaccuracy**.

```{r message = FALSE, warning = FALSE}

#same as in previous for global age
suicide_data_continent = data %>%
  group_by(year, continent) %>%
  summarize(suicide_100k = (sum(suicides_no) / sum(population)) * 100000)
  
  
ggplot(data = suicide_data_continent, 
       aes(x = year, y = suicide_100k, col = factor(continent))) + 
  facet_grid(continent ~ ., scales = "free_y") + 

  geom_line() + 
  geom_point() +
  
  #change labels
  xlab('Year') +
  ylab('Suicides global per 100k')+
  
  #change legend -> from factor(sex) to sex
  labs(color = 'Continent')

```

**Europe** has the most of suicides per 100k, but we see that this trend is **decreasing** over time. However in **America** it does do opposite - **increases**. **Asia oscilates** and is in middle - between America and Europe.
Oceania and Africa is not worth commenting, because we dont have enough data, in my opinion.

#### Age
In plot few sections before we saw that this variable is **equal among all categories** so the results will be accurate too.

```{r message = FALSE, warning = FALSE}
#same as in previous for global age
suicide_data_age = data %>%
  group_by(year, age) %>%
  summarize(suicide_100k = (sum(suicides_no) / sum(population)) * 100000)
  
ggplot(data = suicide_data_age, 
       aes(x = year, y = suicide_100k, col = factor(age))) + 
  facet_grid(age ~ ., scales = "free_y") + 
  
  geom_line() + 
  geom_point() +
  
  #change labels
  xlab('Year') +
  ylab('Suicides global per 100k')+
  
  #change legend -> from factor(age) to age
  labs(color = 'Age')


```

We can see that almost in all age categories the trend is decreasing over time. Also it is obvious, that most of suicides are commited by older people. We can really say: **The older you are, the higher chance of commiting suicide you have.**

### Discussion

Key takeaways are that:
bla bla


## Part 2
From part 1, we have really interesting hypotheses. In this part we will test some of those.

### Age differences
Does the categorical independent variable **age** affect the dependent variable **suicide rates**? In other words we test if the mean in all age groups is the same or not.

H0: The **mean** value of the groups is the same 

H1: The **mean** value of the groups is not the same

#### ANOVA

We can use ANOVA method to test it. More explicitly one-way ANOVA.
```{r message = FALSE, warning = FALSE}
anova_age = aov(suicide_data_age$suicide_100k~suicide_data_age$age)
summary(anova_age)
summary(anova_age)[[1]][["Pr(>F)"]][1]
```
We see really low p-value(far below 0.05). So we reject H0 hypothesis. So **we see that age really affects suicide rates**.

But we have to check our assumptions, because if they are not fulfilled we can't use this result.

#### Shapiro-wilk test

First assumption:

**Does residuals in each group follow a normal distribution?**

We will check this by using Shapiro-Wilk test.

```{r message = FALSE, warning = FALSE}
age_residuals = residuals(object = anova_age)
shapiro.test(age_residuals)
```
Unfortunately, p-value is bellow 0.05 so we have to reject that residuals have normal distribution.

#### Levene's test

**Is variance same in all groups?**

We will check this by using Levene's test.
```{r message = FALSE, warning = FALSE}
library(car)
leveneTest(suicide_data_age$suicide_100k~suicide_data_age$age)
```
Again, p-value is under 0.05 so we have to reject H0. That means that variance is **NOT** same in all groups.

Not a single assumption is fulfilled so ANOVA did not gave us correct results.

But, if ANOVA assumption fails. We can use non-parametric tests. For example: **Kruskal-Wallis test**.

#### Kruskal-wallis test

```{r message = FALSE, warning = FALSE}
library(car)
kruskal.test(suicide_data_age$suicide_100k~suicide_data_age$age)
```
The p-value is below 0.05 so H0 is rejected. 

Now we can safely say that: **Mean value of the groups is not the same - so age affect suicide rate**. 

### Sex differences

Does the categorical independent variable **sex** affect the dependent variable **suicide rates**? In other words we test if the mean in two sex groups is the same or not.

H0: The **mean** value of the groups is the same 

H1: The **mean** value of the groups is not the same

As in first hypothesis, we can use ANOVA method to test it. More explicitly **one-way ANOVA**.

#### ANOVA

```{r message = FALSE, warning = FALSE}
anova_sex = aov(suicide_data_sex$suicide_100k~suicide_data_sex$sex)
summary(anova_sex)
summary(anova_sex)[[1]][["Pr(>F)"]][1]
```
P-value is again under 0.05. We can safely reject H0 hypothesis. 

So **we see that sex really affects suicide rates**.

What about assumptions? We check them as in hypothesis above.

First assumption:

**Does residuals in each group follow a normal distribution?**

We will check this by using Shapiro-Wilk test.

#### Shapiro-wilk test

```{r message = FALSE, warning = FALSE}
sex_residuals = residuals(object = anova_sex)
shapiro.test(sex_residuals)
```
Finally, the p-value is higher than 0.05 :)

We will not reject H0 - so **residuals have normal distribution**.

**Is variance same in all groups?**

We will check this by using Levene's test.

#### Levene's test

```{r message = FALSE, warning = FALSE}
library(car)
leveneTest(suicide_data_sex$suicide_100k~suicide_data_sex$sex)
```
Unfortunately, p-value is under 0.05 so we have to reject H0. That means that variance is **NOT** same in all groups.

Even thought, only this assumption is violated. We still can not rely on ANOVA results. 

We are again forced to use **Kruskal-Wallis test**.

#### Kruskal-wallis test

```{r message = FALSE, warning = FALSE}
library(car)
kruskal.test(suicide_data_sex$suicide_100k~suicide_data_sex$sex)
```
The p-value is below 0.05 so we can safely reject H0. 

Now we are confirmed that: **Mean value of the groups is not the same - so sex affect suicide rate**. 


### Continent differences

Does the categorical independent variable **continent** affect the dependent variable **suicide rates**? In other words we test if the mean in continent groups is the same or not.

H0: The **mean** value of the groups is the same 

H1: The **mean** value of the groups is not the same

As in above hypothesis, we can use **one-way ANOVA method** to test it.

#### ANOVA

```{r message = FALSE, warning = FALSE}
anova_continent = aov(suicide_data_continent$suicide_100k~suicide_data_continent$continent)
summary(anova_continent)
summary(anova_continent)[[1]][["Pr(>F)"]][1]
```
P-value is again under 0.05. We can safely reject H0 hypothesis. 

So **we see that continent really affects suicide rates**.

What about assumptions? We check them as in hypothesis above.

First assumption:

**Does residuals in each group follow a normal distribution?**

We will check this by using Shapiro-Wilk test.

#### Shapiro-wilk test

```{r message = FALSE, warning = FALSE}
continent_residuals = residuals(object = anova_continent)
shapiro.test(continent_residuals)
```
Sadly p-value is a lot lower than 0.05 :(

We will reject H0 - so **residuals dont have normal distribution**.

**Is variance same in all groups?**

We will check this by using Levene's test.

#### Levene's test

```{r message = FALSE, warning = FALSE}
library(car)
leveneTest(suicide_data_continent$suicide_100k~suicide_data_continent$continent)
```
Unfortunately, p-value is under 0.05 so we have to reject H0. That means that variance is **NOT** same in all groups.

All assumptions are again violated. We can not rely on ANOVA results. 

We are again forced to use **Kruskal-Wallis test**.

#### Kruskal-wallis test

```{r message = FALSE, warning = FALSE}
library(car)
kruskal.test(suicide_data_continent$suicide_100k~suicide_data_continent$continent)
```
The p-value is below 0.05 so we can safely reject H0. 

Now we are confirmed that: **Mean value of the groups is not the same - so continent affect suicide rate**. 

## Part 3
Suicide predictive model. Create a model that predicts the suicide rate
based on the remaining variables. Propose a meaningful train/test scenario.
Evaluate and compare the performance of the models, employ cross-validation
to get an unbiased estimate. Utilize feature selection to simplify the models
and improve their performance. Use at least one method that we touched in
the course, but you can compare with other methods too (neural networks,
gradient boosting trees, etc.).

In this part I will create model that will predict the suicide rate based on the remaining variables.

```{r}
library(caret)

learnAndTest <- function(X, Y, modelType, ...) {
  data <- data.frame(X, Y)
   
  train.control <- trainControl(method = "cv", number = 10) # 10-fold cross-validataion
  # Alternative to get more accurate, but slower evaluation:
  # train.control <- trainControl(method = "LOOCV")
 
  # Here we train the model using the versatile `train` function from the caret package
  train(Y ~.,
                 data = data,
                 method = modelType,
                 trControl = train.control,
                 ...)
   
}
```


```{r message = FALSE, warning = FALSE}
library(dplyr)
dependend_matrix <- data$suicides_no
independend_matrix <- select(data, country, year, sex, age, population, gdp_for_year, gdp_per_capita, generation, continent)

print(learnAndTest(independend_matrix, dependend_matrix, "lm"))

```
We can see that our model can explain more than 55% of suicides. However RMSE is around 600 so we did not fit the data perfectly (0 would be the desired value).

We can now compare linear reggression with other method like Neural network, polynomial regression or logistic regression.
Unfortunately, my computer can not handle Polynomial reggresion, I get erro

```{r message = FALSE, warning = FALSE}
library(dplyr)
library(caret)

dependend_matrix <- data$suicides_no
independend_matrix <- select(data, country, year, sex, age, population, gdp_for_year, gdp_per_capita, generation, continent)

#Polynomial regression
#print(learnAndTest(independend_matrix, dependend_matrix, "krlsPoly"))

#Logistic regression
#print(learnAndTest(independend_matrix, dependend_matrix, "logreg"))

#Neural network model
print(learnAndTest(independend_matrix, dependend_matrix, "brnn"))

```

## Discussion
#![Thanks for the attention :) ](finished.PNG)
